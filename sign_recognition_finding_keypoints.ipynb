{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image,  ImageEnhance\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>train</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>height_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ce6ce8a-d191-47d4-97b4-3fc6f9138a73</td>\n",
       "      <td>я</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>1920_1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9e2dbd1-ec2f-4382-a80e-5bca8396a9b1</td>\n",
       "      <td>я</td>\n",
       "      <td>46dd04a1caa75ed3082b573cb5a3ad26</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "      <td>1920_1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f72244c-7379-4403-b7ee-e1b1b8d78d46</td>\n",
       "      <td>я</td>\n",
       "      <td>db573f94204e56e0cf3fc2ea000e5bdc</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>49.0</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "      <td>1280_720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf08e2-4ff6-4183-ba22-446c1cd0b0f8</td>\n",
       "      <td>я</td>\n",
       "      <td>0211b488644476dd0fec656ccb9b74fc</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>50.0</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>1920_1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13a148fc-a546-47ab-b5d0-f9d0c3cce1de</td>\n",
       "      <td>я</td>\n",
       "      <td>2d84da20c251acaeb3186642fcb04f2e</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>1920_1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>74db1174-1314-43c7-bb8a-cc5cce5e2510</td>\n",
       "      <td>редко</td>\n",
       "      <td>f2dc6eab563f93d86629c1cfe479f09d</td>\n",
       "      <td>1440</td>\n",
       "      <td>1440</td>\n",
       "      <td>56.0</td>\n",
       "      <td>False</td>\n",
       "      <td>56</td>\n",
       "      <td>1440_1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>5d742908-98ce-4172-bb2f-02f3595860a4</td>\n",
       "      <td>редко</td>\n",
       "      <td>798aa826b6129d33f72f62d4ba60b681</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>61.0</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>720_1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>dfe2ff4c-98fa-4ead-b861-f499f570a321</td>\n",
       "      <td>месяц</td>\n",
       "      <td>798aa826b6129d33f72f62d4ba60b681</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>720_1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>04856a31-8326-49cb-8e0c-0843c64a1d92</td>\n",
       "      <td>время</td>\n",
       "      <td>798aa826b6129d33f72f62d4ba60b681</td>\n",
       "      <td>720</td>\n",
       "      <td>1280</td>\n",
       "      <td>52.0</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "      <td>720_1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>f0ac4a5e-c438-4f39-a577-2814f423afa7</td>\n",
       "      <td>вчера</td>\n",
       "      <td>3dd2ce2659aada17b976390004ebe322</td>\n",
       "      <td>1920</td>\n",
       "      <td>886</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>1920_886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             attachment_id   text  \\\n",
       "0     5ce6ce8a-d191-47d4-97b4-3fc6f9138a73      я   \n",
       "1     c9e2dbd1-ec2f-4382-a80e-5bca8396a9b1      я   \n",
       "2     3f72244c-7379-4403-b7ee-e1b1b8d78d46      я   \n",
       "3     5adf08e2-4ff6-4183-ba22-446c1cd0b0f8      я   \n",
       "4     13a148fc-a546-47ab-b5d0-f9d0c3cce1de      я   \n",
       "...                                    ...    ...   \n",
       "1995  74db1174-1314-43c7-bb8a-cc5cce5e2510  редко   \n",
       "1996  5d742908-98ce-4172-bb2f-02f3595860a4  редко   \n",
       "1997  dfe2ff4c-98fa-4ead-b861-f499f570a321  месяц   \n",
       "1998  04856a31-8326-49cb-8e0c-0843c64a1d92  время   \n",
       "1999  f0ac4a5e-c438-4f39-a577-2814f423afa7  вчера   \n",
       "\n",
       "                               user_id  height  width  length  train  \\\n",
       "0     185bd3a81d9d618518d10abebf0d17a8    1920   1080    91.0   True   \n",
       "1     46dd04a1caa75ed3082b573cb5a3ad26    1920   1080    58.0   True   \n",
       "2     db573f94204e56e0cf3fc2ea000e5bdc    1280    720    49.0   True   \n",
       "3     0211b488644476dd0fec656ccb9b74fc    1920   1080    50.0   True   \n",
       "4     2d84da20c251acaeb3186642fcb04f2e    1920   1080    27.0   True   \n",
       "...                                ...     ...    ...     ...    ...   \n",
       "1995  f2dc6eab563f93d86629c1cfe479f09d    1440   1440    56.0  False   \n",
       "1996  798aa826b6129d33f72f62d4ba60b681     720   1280    61.0  False   \n",
       "1997  798aa826b6129d33f72f62d4ba60b681     720   1280    58.0  False   \n",
       "1998  798aa826b6129d33f72f62d4ba60b681     720   1280    52.0  False   \n",
       "1999  3dd2ce2659aada17b976390004ebe322    1920    886    35.0  False   \n",
       "\n",
       "      frame_count height_width  \n",
       "0              51    1920_1080  \n",
       "1              58    1920_1080  \n",
       "2              49     1280_720  \n",
       "3              50    1920_1080  \n",
       "4              27    1920_1080  \n",
       "...           ...          ...  \n",
       "1995           56    1440_1440  \n",
       "1996           61     720_1280  \n",
       "1997           58     720_1280  \n",
       "1998           52     720_1280  \n",
       "1999           35     1920_886  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'slovo'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train_100')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test_100')\n",
    "ann_100 = pd.read_csv(os.path.join(DATA_DIR, 'annotations_100.csv'))\n",
    "ann_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_DIR, 'train_data_2.csv'))\n",
    "val_data = pd.read_csv(os.path.join(DATA_DIR, 'val_data_2.csv'))\n",
    "train_data = result = pd.concat([train_data, val_data])\n",
    "test_data = pd.read_csv(os.path.join(DATA_DIR, 'test_data_2.csv'))\n",
    "\n",
    "video_id_train, label_train = train_data['video_file'].values, train_data['label'].values\n",
    "video_id_test, label_test = test_data['video_file'].values, test_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_train = [f'{TRAIN_DIR}\\\\{f}.mp4' for f in video_id_train]\n",
    "video_path_test = [f'{TEST_DIR}\\\\{f}.mp4' for f in video_id_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1200 [01:56<18:25,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 200/1200 [03:49<22:29,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 300/1200 [06:10<15:57,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 400/1200 [08:00<14:51,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 500/1200 [09:51<11:54,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 600/1200 [12:00<16:42,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 600 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 700/1200 [14:49<15:23,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 700 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 800/1200 [17:29<09:09,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 800 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 900/1200 [20:08<07:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 900 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1000/1200 [22:49<05:44,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1100/1200 [25:43<03:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1100 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [28:53<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1200 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [03:19<06:12,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [06:23<02:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [09:18<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 100/500 [02:49<11:14,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [05:35<08:32,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 300/500 [08:20<05:42,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [11:08<02:45,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [13:44<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация утилит MediaPipe для отрисовки и модели Holistic (объединение ключевых точек лица, рук и позы)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Выходная директория\n",
    "output_directory = 'slovo/'\n",
    "\n",
    "# Создание выходной директории, если она не существует\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Инициализация модели MediaPipe Holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "def adjust_landmarks(arr, center):\n",
    "    # Reshape the array to have shape (n, 3)\n",
    "    arr_reshaped = arr.reshape(-1, 3)\n",
    "\n",
    "    # Repeat the center array to have shape (n, 3)\n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1))\n",
    "\n",
    "    # Subtract the center array from the arr array\n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "\n",
    "    # Reshape arr_adjusted back to shape (n*3,)\n",
    "    arr_adjusted = arr_adjusted.reshape(-1)\n",
    "    return arr_adjusted\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    nose = pose[:3]\n",
    "    lh_wrist = lh[:3]\n",
    "    rh_wrist = rh[:3]\n",
    "    pose_adjusted = adjust_landmarks(pose, nose)\n",
    "    lh_adjusted = adjust_landmarks(lh, lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh, rh_wrist)\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted\n",
    "\n",
    "def process_video(video_path, output_path, num_frames=20):\n",
    "    # Инициализация видео ридера\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Выбор кадров для обработки (равномерно распределенные)\n",
    "    frame_indices = np.linspace(0, total_frames - 1, min(num_frames, total_frames), dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while video_reader.isOpened():\n",
    "        success, frame = video_reader.read()\n",
    "        if not success or frame_index > frame_indices[-1]:\n",
    "            break\n",
    "        \n",
    "        if frame_index in frame_indices:\n",
    "            # Преобразование кадра в RGB для MediaPipe\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            # Определение размеров кадра\n",
    "            h, w, _ = frame_rgb.shape\n",
    "            if h > w:\n",
    "                padding = (h - w) // 2\n",
    "                frame_rgb = cv2.copyMakeBorder(frame_rgb, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "            else:\n",
    "                padding = (w - h) // 2\n",
    "                frame_rgb = cv2.copyMakeBorder(frame_rgb, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "            # Выполнение оценки holistic (лицо, руки, поза)\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # Извлечение ключевых точек\n",
    "            pose_adjusted, lh_adjusted, rh_adjusted = extract_keypoints(results)\n",
    "            frames.append([frame_index, pose_adjusted, lh_adjusted, rh_adjusted])\n",
    "        \n",
    "        frame_index += 1\n",
    "\n",
    "    # Освобождение ресурсов\n",
    "    video_reader.release()\n",
    "\n",
    "    # Добавление пустых кадров, если необходимо\n",
    "    while len(frames) < num_frames:\n",
    "        frames.append([None, np.zeros(33*3), np.zeros(21*3), np.zeros(21*3)])    \n",
    "\n",
    "    # Создание DataFrame из извлеченных ключевых точек\n",
    "    df = pd.DataFrame(frames, columns=['frame', 'pose', 'left_hand', 'right_hand'])\n",
    "\n",
    "    # Сохранение DataFrame в parquet файл\n",
    "    df.to_parquet(output_path)\n",
    "\n",
    "def process_videos(video_paths, output_subdir):\n",
    "    os.makedirs(output_subdir, exist_ok=True)\n",
    "    count = 0\n",
    "    for video_path in tqdm(video_paths):\n",
    "        filename = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_subdir, f'{os.path.splitext(filename)[0]}.parquet')\n",
    "        process_video(video_path, output_path)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f'Processed {count} videos')\n",
    "\n",
    "# Обработка тренировочных, валидационных и тестовых видео\n",
    "process_videos(video_path_train, os.path.join(output_directory, 'train_keypoints_5'))\n",
    "process_videos(video_path_test, os.path.join(output_directory, 'test_keypoints_5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Выходная директория\n",
    "output_directory = 'slovo/'\n",
    "\n",
    "# Создание выходной директории, если она не существует\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Инициализация модели MediaPipe Holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "def adjust_landmarks(arr, center):\n",
    "    arr_reshaped = arr.reshape(-1, 3)\n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1))\n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "    arr_adjusted = arr_adjusted.reshape(-1)\n",
    "    return arr_adjusted\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    nose = pose[:3]\n",
    "    lh_wrist = lh[:3]\n",
    "    rh_wrist = rh[:3]\n",
    "    pose_adjusted = adjust_landmarks(pose, nose)\n",
    "    lh_adjusted = adjust_landmarks(lh, lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh, rh_wrist)\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted\n",
    "\n",
    "def flip_keypoints(keypoints):\n",
    "    flipped = keypoints.copy()\n",
    "    flipped[::3] = 1 - keypoints[::3]  # Flip x-coordinates\n",
    "    return flipped\n",
    "\n",
    "def process_frame(frame, flip=False):\n",
    "    if flip:\n",
    "        frame = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w, _ = frame_rgb.shape\n",
    "    if h > w:\n",
    "        padding = (h - w) // 2\n",
    "        frame_rgb = cv2.copyMakeBorder(frame_rgb, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    else:\n",
    "        padding = (w - h) // 2\n",
    "        frame_rgb = cv2.copyMakeBorder(frame_rgb, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    results = holistic.process(frame_rgb)\n",
    "\n",
    "    pose_adjusted, lh_adjusted, rh_adjusted = extract_keypoints(results)\n",
    "    \n",
    "    if flip:\n",
    "        pose_adjusted = flip_keypoints(pose_adjusted)\n",
    "        lh_adjusted, rh_adjusted = rh_adjusted, lh_adjusted  # Swap left and right hand keypoints\n",
    "\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted\n",
    "\n",
    "def process_video(video_path, output_path, num_frames=20):\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, min(num_frames, total_frames), dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while video_reader.isOpened():\n",
    "        success, frame = video_reader.read()\n",
    "        if not success or frame_index > frame_indices[-1]:\n",
    "            break\n",
    "\n",
    "        if frame_index in frame_indices:\n",
    "            for flip in [False, True]:  # Process both original and flipped frames\n",
    "                pose_adjusted, lh_adjusted, rh_adjusted = process_frame(frame, flip)\n",
    "                frames.append([frame_index, pose_adjusted, lh_adjusted, rh_adjusted, flip])\n",
    "        \n",
    "        frame_index += 1\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    # Добавление пустых кадров, если необходимо\n",
    "    while len(frames) < num_frames * 2:  # Учитываем, что обрабатываем и оригинальные и перевёрнутые кадры\n",
    "        frames.append([None, np.zeros(33*3), np.zeros(21*3), np.zeros(21*3), False])    \n",
    "        frames.append([None, np.zeros(33*3), np.zeros(21*3), np.zeros(21*3), True])        \n",
    "        \n",
    "    df = pd.DataFrame(frames, columns=['frame', 'pose', 'left_hand', 'right_hand', 'flip'])\n",
    "    df.to_parquet(output_path)\n",
    "\n",
    "def process_videos(video_paths, output_subdir):\n",
    "    os.makedirs(output_subdir, exist_ok=True)\n",
    "    count = 0\n",
    "    for video_path in tqdm(video_paths):\n",
    "        filename = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_subdir, f'{os.path.splitext(filename)[0]}.parquet')\n",
    "        process_video(video_path, output_path)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f'Processed {count} videos')\n",
    "\n",
    "# Обработка тренировочных, валидационных и тестовых видео\n",
    "process_videos(video_path_train, os.path.join(output_directory, 'train_keypoints_6'))\n",
    "process_videos(video_path_test, os.path.join(output_directory, 'test_keypoints_6'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация утилит MediaPipe для отрисовки и модели Holistic (объединение ключевых точек лица, рук и позы)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Выходная директория\n",
    "output_directory = 'slovo/'\n",
    "\n",
    "# Создание выходной директории, если она не существует\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Инициализация модели MediaPipe Holistic\n",
    "holistic = mp_holistic.Holistic()\n",
    "\n",
    "def adjust_landmarks(arr, center):\n",
    "    # Reshape the array to have shape (n, 3)\n",
    "    arr_reshaped = arr.reshape(-1, 3)\n",
    "\n",
    "    # Repeat the center array to have shape (n, 3)\n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1))\n",
    "\n",
    "    # Subtract the center array from the arr array\n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "\n",
    "    # Reshape arr_adjusted back to shape (n*3,)\n",
    "    arr_adjusted = arr_adjusted.reshape(-1)\n",
    "    return arr_adjusted\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    nose = pose[:3]\n",
    "    lh_wrist = lh[:3]\n",
    "    rh_wrist = rh[:3]\n",
    "    pose_adjusted = adjust_landmarks(pose, nose)\n",
    "    lh_adjusted = adjust_landmarks(lh, lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh, rh_wrist)\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted\n",
    "\n",
    "def enhance_frame(frame):\n",
    "    frame_pil = Image.fromarray(frame)\n",
    "    \n",
    "    # Увеличение контрастности\n",
    "    contrast_enhancer = ImageEnhance.Contrast(frame_pil)\n",
    "    frame_contrast = contrast_enhancer.enhance(1.5)\n",
    "    \n",
    "    # Увеличение резкости\n",
    "    sharpness_enhancer = ImageEnhance.Sharpness(frame_pil)\n",
    "    frame_sharpness = sharpness_enhancer.enhance(2.0)\n",
    "    \n",
    "    # Увеличение яркости\n",
    "    brightness_enhancer = ImageEnhance.Brightness(frame_pil)\n",
    "    frame_brightness = brightness_enhancer.enhance(1.5)\n",
    "    \n",
    "    # Флиппинг\n",
    "    frame_flipped = frame_pil.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    return frame_contrast, frame_sharpness, frame_brightness, frame_flipped\n",
    "\n",
    "def process_video(video_path, output_path, num_frames=20):\n",
    "    # Инициализация видео ридера\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Выбор кадров для обработки (равномерно распределенные)\n",
    "    frame_indices = np.linspace(0, total_frames - 1, min(num_frames, total_frames), dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while video_reader.isOpened():\n",
    "        success, frame = video_reader.read()\n",
    "        if not success or frame_index > frame_indices[-1]:\n",
    "            break\n",
    "        \n",
    "        if frame_index in frame_indices:\n",
    "            # Преобразование кадра в RGB для MediaPipe\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            # Определение размеров кадра\n",
    "            h, w, _ = frame_rgb.shape\n",
    "            if h > w:\n",
    "                padding = (h - w) // 2\n",
    "                frame_rgb = cv2.copyMakeBorder(frame_rgb, 0, 0, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "            else:\n",
    "                padding = (w - h) // 2\n",
    "                frame_rgb = cv2.copyMakeBorder(frame_rgb, padding, padding, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "            # Выполнение оценки holistic (лицо, руки, поза)\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # Извлечение ключевых точек из оригинального кадра\n",
    "            pose_adjusted, lh_adjusted, rh_adjusted = extract_keypoints(results)\n",
    "            frames.append([frame_index, 'original', pose_adjusted, lh_adjusted, rh_adjusted])\n",
    "            \n",
    "            # Применение дополнительных преобразований к кадру\n",
    "            frame_contrast, frame_sharpness, frame_brightness, frame_flipped = enhance_frame(frame_rgb)\n",
    "            for variation_name, enhanced_frame in zip(['contrast', 'sharpness', 'brightness', 'flipped'],\n",
    "                                                      [frame_contrast, frame_sharpness, frame_brightness, frame_flipped]):\n",
    "                enhanced_frame_rgb = np.array(enhanced_frame)\n",
    "                results = holistic.process(enhanced_frame_rgb)\n",
    "                pose_adjusted, lh_adjusted, rh_adjusted = extract_keypoints(results)\n",
    "                frames.append([frame_index, variation_name, pose_adjusted, lh_adjusted, rh_adjusted])\n",
    "        \n",
    "        frame_index += 1\n",
    "\n",
    "    # Освобождение ресурсов\n",
    "    video_reader.release()\n",
    "\n",
    "    # Добавление пустых кадров, если необходимо\n",
    "    while len(frames) < num_frames * 5:\n",
    "        for i in ['original', 'contrast', 'sharpness', 'brightness', 'flipped']:\n",
    "            frames.append([None, i, np.zeros(33*3), np.zeros(21*3), np.zeros(21*3)])    \n",
    "\n",
    "    # Создание DataFrame из извлеченных ключевых точек\n",
    "    df = pd.DataFrame(frames, columns=['frame', 'variation', 'pose', 'left_hand', 'right_hand'])\n",
    "\n",
    "    # Сохранение DataFrame в parquet файл\n",
    "    df.to_parquet(output_path)\n",
    "\n",
    "def process_videos(video_paths, output_subdir):\n",
    "    os.makedirs(output_subdir, exist_ok=True)\n",
    "    count = 0\n",
    "    for video_path in tqdm(video_paths):\n",
    "        filename = os.path.basename(video_path)\n",
    "        output_path = os.path.join(output_subdir, f'{os.path.splitext(filename)[0]}.parquet')\n",
    "        process_video(video_path, output_path)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f'Processed {count} videos')\n",
    "\n",
    "# Обработка тренировочных и тестовых видео\n",
    "process_videos(video_path_train, os.path.join(output_directory, 'train_keypoints_7'))\n",
    "process_videos(video_path_test, os.path.join(output_directory, 'test_keypoints_7'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it_academy_fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
